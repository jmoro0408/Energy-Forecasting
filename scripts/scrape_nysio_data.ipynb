{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomli\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_TOML_DIR = Path(Path.cwd().parent, \"data\", \"nysio_links.toml\")\n",
    "WEATHER_SAVE_DIR = Path(Path.cwd().parent, \"data\", \"raw_data\", \"weather\")\n",
    "LOAD_SAVE_DIR = Path(Path.cwd().parent, \"data\", \"raw_data\", \"load\")\n",
    "GET_WEATHER_DATA = False  # Flag to make sure the data isnt needlessly re-downloaded\n",
    "GET_LOAD_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zip_data(url: str, save_dir: Path) -> None:\n",
    "    \"\"\"Downloads and unzips zip files downloaded from the internet.\n",
    "    Returns None if page is 404.\n",
    "\n",
    "    Args:\n",
    "        url (str): url pointing to zip file\n",
    "        save_dir (Path): directory to save unzipped files\n",
    "\n",
    "    Returns:\n",
    "        None: None\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        return None\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall(save_dir)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_size(root_dir: Path) -> int:\n",
    "    \"\"\"Returns the size of a folder in mb.\n",
    "    Not recursive, does not include sub directories.\n",
    "\n",
    "    Args:\n",
    "        root_dir (Path): folder directory\n",
    "\n",
    "    Returns:\n",
    "        int: folder size in mb\n",
    "    \"\"\"\n",
    "    return (\n",
    "        sum(f.stat().st_size for f in root_dir.glob(\"**/*\") if f.is_file()) / 1_000_000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(URL_TOML_DIR, mode=\"rb\") as fp:\n",
    "    urls_dict = tomli.load(fp)\n",
    "weather_stem = urls_dict[\"urls\"][\"weather_stem\"]\n",
    "load_stem = urls_dict[\"urls\"][\"load_stem\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather zip files are constructed in the following format:\n",
    "\n",
    "* \"http://mis.nyiso.com/public/csv/lfweather/\"\n",
    "* date of file in yearmonthday format: \"20230601\"\n",
    "* \"lfweather_csv.zip\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather urls are bucketed into months, so the date portion of the url is always 1. \n",
    "From the website, we can see weather data from 2008-09 through to 2023-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(x) for x in range(2008, 2024)]\n",
    "months = [str(x) for x in range(1, 13)]\n",
    "months = [\"0\" + x if int(x) < 10 else x for x in months]\n",
    "days = [\"01\"]\n",
    "# combining and concatenating all possible dates into the required format\n",
    "# Note some dates will be invalid, e.g 2008 before 09.\n",
    "# We will handle this in the requests function\n",
    "all_possible_dates = [\"\".join(x) for x in list(product(years, months, days))]\n",
    "all_weather_urls = [\n",
    "    weather_stem + date + \"lfweather_csv.zip\" for date in all_possible_dates\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_WEATHER_DATA:\n",
    "    for url in all_weather_urls:\n",
    "        get_zip_data(url, WEATHER_SAVE_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The load zip files are constructed in the following format:\n",
    "\n",
    "* \"http://mis.nyiso.com/public/csv/pal/\"\n",
    "* date of file in yearmonthday format: \"20230601\"\n",
    "* \"pal_csv.zip\"\n",
    "\n",
    "The Load data goes back to 2001-05, we'll grab everything even though the weather data only goes back to 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_years = [str(x) for x in range(2001, 2024)]\n",
    "all_possible_dates = [\"\".join(x) for x in list(product(years, months, days))]\n",
    "all_load_urls = [load_stem + date + \"pal_csv.zip\" for date in all_possible_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_LOAD_DATA:\n",
    "    for url in all_load_urls:\n",
    "        get_zip_data(url, LOAD_SAVE_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5615\n",
      "5351\n"
     ]
    }
   ],
   "source": [
    "print(len(list(Path.glob(LOAD_SAVE_DIR, \"*.csv\"))))\n",
    "print(len(list(Path.glob(WEATHER_SAVE_DIR, \"*.csv\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913.177374\n",
      "34.879922\n"
     ]
    }
   ],
   "source": [
    "print(get_folder_size(LOAD_SAVE_DIR))\n",
    "print(get_folder_size(WEATHER_SAVE_DIR))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5615 csv files found for load data, totalling 913 mb. \n",
    "\n",
    "5351 csv files found for weather data, totalling 34 mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
